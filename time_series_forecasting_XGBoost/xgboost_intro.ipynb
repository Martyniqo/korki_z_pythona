{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue;\">Czym jest XGBoost? 🎯</span>\n",
    "\n",
    "https://www.kaggle.com/code/robikscube/time-series-forecasting-with-machine-learning-yt\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) to bardzo wydajna i popularna biblioteka do tworzenia modeli uczenia maszynowego. Jest szczególnie wykorzystywana w konkursach na platformach takich jak Kaggle, ponieważ pozwala osiągnąć bardzo dobre wyniki przy minimalnym dostrajaniu parametrów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 **Jak działa XGBoost?**\n",
    "XGBoost opiera się na metodzie gradient boosting, która działa w następujących krokach:\n",
    "1. **Model bazowy:** Na początku tworzymy prosty model (np. drzewo decyzyjne), który próbuje przewidzieć wynik.\n",
    "2. **Resztki:** Następnie obliczamy błędy (resztki), czyli różnicę między przewidywaniami a rzeczywistymi wynikami.\n",
    "3. **Kolejne modele:** Tworzymy kolejne modele, które uczą się na podstawie tych błędów, aby je skorygować.\n",
    "4. **Sumowanie:** Łączymy przewidywania wszystkich modeli, aby uzyskać końcową prognozę.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 **Cechy XGBoost**\n",
    "- **Szybkość:** Wykorzystuje optymalizacje sprzętowe i równoległe przetwarzanie.\n",
    "- **Efektywność:** Radzi sobie z brakującymi danymi oraz dużymi zbiorami danych.\n",
    "- **Elastyczność:** Obsługuje klasyfikację, regresję i ranking.\n",
    "- **Kontrola nadfittingu:** Wbudowane mechanizmy, takie jak regularyzacja, zapobiegają przeuczeniu modelu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 **Dlaczego warto używać XGBoost?**\n",
    "1. **Wysoka dokładność:** Wygrywa wiele konkursów na Kaggle.\n",
    "2. **Skalowalność:** Może być używany zarówno na małych, jak i bardzo dużych zbiorach danych.\n",
    "3. **Wsparcie społeczności:** Jest dobrze udokumentowany i posiada aktywną społeczność użytkowników.\n",
    "\n",
    "---\n",
    "\n",
    "### 👩‍💻 **Przykład w Pythonie**\n",
    "```python\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Załaduj dane\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Utwórz model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Sprawdź dokładność\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność modelu: {accuracy:.2f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **Podsumowanie**\n",
    "XGBoost to świetne narzędzie do tworzenia potężnych modeli uczenia maszynowego. Dzięki swoim zaawansowanym funkcjom i prostocie obsługi jest idealne zarówno dla początkujących, jak i zaawansowanych użytkowników. 💡\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
